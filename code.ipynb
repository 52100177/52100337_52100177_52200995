{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Giới thiệu về bài toán : \n",
    "Xây dựng các mô hình có khả năng dự đoán mức độ béo phì của một người từ các thông tin đầu vào cần thiết.\n",
    "\n",
    "Bộ dữ liệu bao gồm dữ liệu để ước tính mức độ béo phì ở các cá nhân từ các quốc gia Mexico, Peru và Colombia, dựa trên thói quen ăn uống và tình trạng thể chất của họ.\n",
    "\n",
    "Dữ liệu chứa 17 thuộc tính và 2111 bản ghi, các bản ghi được gán nhãn bằng biến lớp NObesity (Mức độ béo phì), cho phép phân loại dữ liệu bằng các giá trị Insufficient Weight (Thiếu cân), Normal Weight (Cân nặng bình thường), Overweight Level I (Thừa cân cấp độ I), Overweight Level II (Thừa cân cấp độ II), Obesity Type I (Béo phì loại I), Obesity Type II (Béo phì loại II) và Obesity Type III (Béo phì loại III)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PART 1: PHÂN TÍCH, TÌM HIỂU VỀ BỘ DỮ LIỆU CỦA BÀI TOÁN\n",
    "1. Ý nghĩa các features và đánh giá mức độ quan trọng của từng features trong mục tiêu của bài toán\n",
    "2. Vẽ có đồ thị trực quan cho số liệu của các đặc trưng, đồng thời hiểu rõ hơn về bài toán"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 Ý nghĩa của các features\n",
    "Mổi mẫu trong bộ dữ liệu bao gồm có 16 features bao gồm :\n",
    "1. Gender (Categorical) : giới tính\n",
    "2. Age (Continuous): tuổi\n",
    "3. Height (Continuous): chiều cao\n",
    "4. Weight (Continuous): cân nặng\n",
    "5. family_history_with_overweight (Binary) : Có thành viên nào trong gia đình đã từng hoặc đang mắc bệnh béo phì hay không\n",
    "6. FAVC (Binary): Có tiêu thụ thực phẩm nhiều calo thường xuyên không ?\n",
    "7. FCVC (Categorical): Mức độ thường xuyên kết hợp rau củ quả trong bữa ăn hay không\n",
    "8. NCP (Continuous): Có bao nhiêu bữa ăn chính trong một ngày\n",
    "9. CAEC (Categorical): Mức độ thường xuyên ăn các món ăn vặt khác ngoài bữa ăn\n",
    "10. SMOKE (Binary): Có hút thuốc hay không ?\n",
    "11. CH20 (Continuous): Lượng nước tiêu thụ mỗi ngày\n",
    "12. SCC (Binary): Có kiểm soát lượng calo tiêu thụ mỗi ngày không ?\n",
    "13. FAF (Continuous): Thời gian tham tham gia các hoạt động thể chất trong ngày ?\n",
    "14. TUE (Integer): Số giờ dành thời gian có các thiệt bị công nghệ mỗi ngày\n",
    "15. CALC (Categorical): Mức độ thường xuyên sử dụng đồ uống có cồn\n",
    "16. MTRANS (Categorical): Loại phương tiện đi lại thường được sử dụng\n",
    "\n",
    "Và một target là:\n",
    "\n",
    "17. NObeyesdad (Categorical) bao gồm các giá trị:\n",
    "\n",
    "    1. Insufficient Weight : Thiếu cân\n",
    "\n",
    "    2. Normal Weight : Cân nặng bình thường\n",
    "\n",
    "    3. Overweight Level I : Thừa cân mức độ I\n",
    "\n",
    "    4. Overweight Level II: Thừa cân mức độ II\n",
    "\n",
    "    5. Obesity Type I : Béo phì mức độ I\n",
    "\n",
    "    6. Obesity Type II : Béo phì mức độ II\n",
    "    \n",
    "    7. Obesity Type III : Béo phì  mức độ III"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PART 2: ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense,Dropout,BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ĐỌC DỮ LIỆU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "filename = \"data.csv\"\n",
    "df = pd.read_csv(filename,delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Gender', 'Age', 'Height', 'Weight', 'family_history_with_overweight', 'FAVC', 'FCVC', 'NCP', 'CAEC', 'SMOKE', 'CH2O', 'SCC', 'FAF', 'TUE', 'CALC', 'MTRANS']\n",
      "NObeyesdad\n"
     ]
    }
   ],
   "source": [
    "#Thông tin về features và target\n",
    "#Get the list of column names\n",
    "columns = df.columns.tolist()\n",
    "\n",
    "#The name of feature and target columns\n",
    "features = columns[:-1]\n",
    "target = columns[-1]\n",
    "\n",
    "print(features)\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THỰC HIỆN CÁC THAO TÁC TIỀN XỬ LÝ CHO DỮ LIỆU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLEANING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Xoá dữ liệu trùng lập nếu có\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "#Xoá các dòng có dữ liệu bị thiếu\n",
    "df.dropna(inplace=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA TRANSFORMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chọn ra các cột cần được transform\n",
    "\n",
    "#Tui chưa enconde biến target -> Tuỳ nhu cầu,coi nếu cần thì thêm vào đây để encode nhe\n",
    "columns_to_encode = ['Gender', 'family_history_with_overweight','FAVC','CAEC', 'SMOKE','SCC','CALC', 'MTRANS']\n",
    "# Khỏi tạo LabelEncoder object\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "#Thực hiện label encoder cho mỗi cột\n",
    "for column in columns_to_encode:\n",
    "    df[column] = label_encoder.fit_transform(df[column])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA NORMALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data normalization\n",
    "\n",
    "#Chọn ra các cột cần được chuyển hoá\n",
    "columns_to_normalized = ['Age', 'Height', 'Weight', 'CH2O','FAF']\n",
    "\n",
    "#Khởi tạo MinMaxScaler object\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Thực hiện chuẩn hoá các cột đã được chọn\n",
    "df[columns_to_normalized] = scaler.fit_transform(df[columns_to_normalized])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trích xuất các features column\n",
    "X = df[features]\n",
    "#Trích xuất label column\n",
    "y = df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CÁC MÔ HÌNH THUỘC ENSEMBLE LEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Độ chính xác của mô hình Random Forest: 0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "#RANDOM FOREST\n",
    "# Tạo mô hình Random Forest với 100 cây quyết định\n",
    "rf_model = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# Huấn luyện mô hình trên tập huấn luyện\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Dự đoán nhãn cho tập kiểm tra\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Đánh giá hiệu suất của mô hình bằng độ chính xác\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Độ chính xác của mô hình Random Forest:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Để tránh overfitting cho mô hình random forest, ta thường sẽ tùy chỉnh các tham số sau trước khi xây dựng mô hình như: số lượng cây (n_estimators), độ sâu của cây (max_depth), số mẫu tại nút phân chia (min_samples_split),... Các tham số này ảnh hưởng đến overfitting và hiệu suất của mô hình, nên ta sẽ dùng nhiều loại giá trị khác nhau cho các tham số để tìm ra tham số nào tối ưu nhất. Tuy nhiên, việc chạy nhều mô hình như vậy sẽ gây mấy thời gian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 0.9562550574526621\n",
      "Best Parameters: {'max_depth': 15, 'min_samples_split': 5, 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "#tránh overfitting bằng phương pháp Đánh giá và tinh chỉnh siêu tham số\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [2,5, 10, 15],\n",
    "    'min_samples_split': [7,2, 5, 10]\n",
    "}\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_params = grid_search.best_params_\n",
    "rf = RandomForestClassifier(**best_params)\n",
    "print(\"Best Accuracy:\", grid_search.best_score_)\n",
    "print(\"Best Parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Độ chính xác của mô hình AdaBoost: 0.32057416267942584\n"
     ]
    }
   ],
   "source": [
    "#ADAPTIVE BOOSTING\n",
    "# Tạo mô hình AdaBoost với 100 cây quyết định làm bộ phân loại cơ bản\n",
    "adaboost_model = AdaBoostClassifier(n_estimators=100,random_state=42)\n",
    "\n",
    "# Huấn luyện mô hình trên tập huấn luyện\n",
    "adaboost_model.fit(X_train, y_train)\n",
    "\n",
    "# Dự đoán nhãn cho tập kiểm tra\n",
    "y_pred = adaboost_model.predict(X_test)\n",
    "\n",
    "# Đánh giá hiệu suất của mô hình bằng độ chính xác\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Độ chính xác của mô hình AdaBoost:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Áp dụng kỹ thuật regularization để làm giảm overfitting giúp tăng hiệu suất của mô hình. Kỹ thuật này nhầm giới hạn độ phức tạp của các weak learners trong AdaBoost, như là giới hạn độ sâu của cây quyết định."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Độ chính xác của mô hình AdaBoost: 0.9425837320574163\n"
     ]
    }
   ],
   "source": [
    "#mô hình khi được giảm overfitting\n",
    "adaboost_model = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=5), n_estimators=50, random_state=42)\n",
    "\n",
    "# Huấn luyện mô hình trên tập huấn luyện\n",
    "adaboost_model.fit(X_train, y_train)\n",
    "\n",
    "# Dự đoán nhãn cho tập kiểm tra\n",
    "y_pred = adaboost_model.predict(X_test)\n",
    "\n",
    "# Đánh giá hiệu suất của mô hình bằng độ chính xác\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Độ chính xác của mô hình AdaBoost:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Độ chính xác của mô hình Gradient Boosting: 0.9569377990430622\n"
     ]
    }
   ],
   "source": [
    "# Tạo mô hình Gradient Boosting với 100 cây quyết định\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Huấn luyện mô hình trên tập huấn luyện\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Dự đoán nhãn cho tập kiểm tra\n",
    "y_pred = gb_model.predict(X_test)\n",
    "\n",
    "# Đánh giá hiệu suất của mô hình bằng độ chính xác\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Độ chính xác của mô hình Gradient Boosting:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tiếp tục áp dụng kỹ thuật regularization để giảm overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Độ chính xác của mô hình Gradient Boosting: 0.9688995215311005\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting tinh chỉnh tham số để giảm overfitting\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100,max_depth=7, min_samples_leaf=5, random_state=42)\n",
    "\n",
    "# Huấn luyện mô hình trên tập huấn luyện\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Dự đoán nhãn cho tập kiểm tra\n",
    "y_pred = gb_model.predict(X_test)\n",
    "\n",
    "# Đánh giá hiệu suất của mô hình bằng độ chính xác\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Độ chính xác của mô hình Gradient Boosting:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MÔ HÌNH FEED FORWARD NEURAL NETWORK "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "Độ chính xác của mô hình Neural Network: 0.9545454545454546\n"
     ]
    }
   ],
   "source": [
    "# Tạo một đối tượng LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Áp dụng LabelEncoder cho nhãn\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# One-hot encode nhãn\n",
    "y_ffnn_train = to_categorical(y_train_encoded)\n",
    "y_ffnn_test = to_categorical(y_test_encoded)\n",
    "\n",
    "# Tạo mô hình mạng neural\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_dim=16)) # Lớp đầu vào với 16 đặc trưng\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(7, activation='softmax')) # Lớp đầu ra với 7 lớp nhãn\n",
    "\n",
    "# Biên dịch mô hình\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Huấn luyện mô hình\n",
    "model.fit(X_train, y_ffnn_train, epochs=100, batch_size=32, verbose=0)\n",
    "\n",
    "# Dự đoán nhãn cho tập kiểm tra\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = y_pred.argmax(axis=1)\n",
    "\n",
    "# Đánh giá hiệu suất của mô hình bằng độ chính xác\n",
    "accuracy = accuracy_score(y_ffnn_test.argmax(axis=1), y_pred)\n",
    "print(\"Độ chính xác của mô hình Neural Network:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sử dụng Regularization L1 (Lasso) tạo ra các trọng số thưa thớt (sparse) để giảm overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 2ms/step\n",
      "Độ chính xác của mô hình Neural Network: 0.9617224880382775\n"
     ]
    }
   ],
   "source": [
    "# Tạo một đối tượng LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Áp dụng LabelEncoder cho nhãn\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# One-hot encode nhãn\n",
    "y_ffnn_train = to_categorical(y_train_encoded)\n",
    "y_ffnn_test = to_categorical(y_test_encoded)\n",
    "\n",
    "# Tạo mô hình mạng neural\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_dim=16, kernel_regularizer=regularizers.l1(0.01))) # Lớp đầu vào với 16 đặc trưng\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(7, activation='softmax')) # Lớp đầu ra với 7 lớp nhãn\n",
    "\n",
    "# Biên dịch mô hình\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Huấn luyện mô hình\n",
    "model.fit(X_train, y_ffnn_train, epochs=100, batch_size=32, verbose=0)\n",
    "\n",
    "# Dự đoán nhãn cho tập kiểm tra\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = y_pred.argmax(axis=1)\n",
    "\n",
    "# Đánh giá hiệu suất của mô hình bằng độ chính xác\n",
    "accuracy = accuracy_score(y_ffnn_test.argmax(axis=1), y_pred)\n",
    "print(\"Độ chính xác của mô hình Neural Network:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MÔ HÌNH LONG SHORT-TERM MEMORY THUỘC LOẠI RECCURENT NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "53/53 [==============================] - 6s 5ms/step - loss: 1.9113 - accuracy: 0.1983\n",
      "Epoch 2/10\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 1.8230 - accuracy: 0.2972\n",
      "Epoch 3/10\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 1.6894 - accuracy: 0.3996\n",
      "Epoch 4/10\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 1.5316 - accuracy: 0.4446\n",
      "Epoch 5/10\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 1.3975 - accuracy: 0.4883\n",
      "Epoch 6/10\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 1.3018 - accuracy: 0.5039\n",
      "Epoch 7/10\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 1.2242 - accuracy: 0.5285\n",
      "Epoch 8/10\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 1.1657 - accuracy: 0.5542\n",
      "Epoch 9/10\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 1.1213 - accuracy: 0.5704\n",
      "Epoch 10/10\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 1.0777 - accuracy: 0.5992\n",
      "14/14 [==============================] - 1s 3ms/step - loss: 1.0522 - accuracy: 0.5981\n",
      "Độ chính xác của mô hình Neural Network: 0.5980861186981201\n"
     ]
    }
   ],
   "source": [
    "# thay đỏi kích thước của tập dữ liệu để phù hợp khi xét timesteps bằng 1\n",
    "X_train_rnn = X_train.to_numpy()\n",
    "X_train_rnn = X_train_rnn.reshape(-1, 1, X_train_rnn.shape[1]) \n",
    " \n",
    "\n",
    "X_test_rnn = X_test.to_numpy()\n",
    "X_test_rnn = X_test_rnn.reshape(-1, 1, X_test_rnn.shape[1]) \n",
    "\n",
    "# Xây dựng mô hình LSMT\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(units=64, input_shape=(1,16)))\n",
    "model.add(Dense(units=7, activation='sigmoid'))\n",
    "\n",
    "# Compile mô hình\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Huấn luyện mô hình\n",
    "model.fit(X_train_rnn, y_ffnn_train, epochs=10, batch_size=32)\n",
    "\n",
    "# Đánh giá mô hình trên tập kiểm tra\n",
    "loss, accuracy = model.evaluate(X_test_rnn, y_ffnn_test)\n",
    "print(\"Độ chính xác của mô hình Neural Network:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sử dụng lớp BatchNormalization sau mỗi lớp LSTM để ổn định đầu ra của các lớp và giảm overfitting\n",
    "Sử dụng lớp Dropout sau mỗi lớp LSTM để ngẫu nhiên tắt một phần các đơn vị đầu ra trong quá trình huấn luyện. Điều này giúp giảm khả năng mô hình tinh chỉnh quá mức vào các mẫu huấn luyện cụ thể và cải thiện khả năng tổng quát hóa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "53/53 [==============================] - 5s 6ms/step - loss: 1.3519 - accuracy: 0.5063\n",
      "Epoch 2/10\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.8957 - accuracy: 0.6800\n",
      "Epoch 3/10\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.7262 - accuracy: 0.7549\n",
      "Epoch 4/10\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.6374 - accuracy: 0.7825\n",
      "Epoch 5/10\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.5562 - accuracy: 0.8095\n",
      "Epoch 6/10\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.4999 - accuracy: 0.8322\n",
      "Epoch 7/10\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.4481 - accuracy: 0.8478\n",
      "Epoch 8/10\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.4033 - accuracy: 0.8646\n",
      "Epoch 9/10\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.3753 - accuracy: 0.8742\n",
      "Epoch 10/10\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.3727 - accuracy: 0.8718\n",
      "14/14 [==============================] - 1s 3ms/step - loss: 0.6093 - accuracy: 0.8325\n",
      "Độ chính xác của mô hình Neural Network: 0.8325358629226685\n"
     ]
    }
   ],
   "source": [
    "# thay đỏi kích thước của tập dữ liệu để phù hợp khi xét timesteps bằng 1\n",
    "X_train_rnn = X_train.to_numpy()\n",
    "X_train_rnn = X_train_rnn.reshape(-1, 1, X_train_rnn.shape[1]) \n",
    " \n",
    "\n",
    "X_test_rnn = X_test.to_numpy()\n",
    "X_test_rnn = X_test_rnn.reshape(-1, 1, X_test_rnn.shape[1]) \n",
    "\n",
    "# Xây dựng mô hình LSMT\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(units=64, input_shape=(1,16), return_sequences=True))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.01))\n",
    "model.add(LSTM(64))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(units=7, activation='sigmoid'))\n",
    "\n",
    "# Compile mô hình\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Huấn luyện mô hình\n",
    "model.fit(X_train_rnn, y_ffnn_train, epochs=10, batch_size=32)\n",
    "\n",
    "# Đánh giá mô hình trên tập kiểm tra\n",
    "loss, accuracy = model.evaluate(X_test_rnn, y_ffnn_test)\n",
    "print(\"Độ chính xác của mô hình Neural Network:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
